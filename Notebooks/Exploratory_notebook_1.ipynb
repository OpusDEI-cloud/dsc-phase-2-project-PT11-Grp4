{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515d3d29",
   "metadata": {},
   "source": [
    "# Comprehensive Movie Data Analysis\n",
    "\n",
    "This notebook integrates all available movie datasets, including the IMDB database, to answer the business question:\n",
    "\n",
    "**\"What kinds of movies should a new studio produce for financial success?\"**\n",
    "\n",
    "We focus on:\n",
    "- Genre profitability\n",
    "- Budget-revenue relationships\n",
    "- Impact of review scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb87e73",
   "metadata": {},
   "source": [
    "## 1. Load All Datasets Including IMDB Database\n",
    "\n",
    "We load all CSV/TSV files and connect to the IMDB SQLite database. Relevant IMDB tables (`movie_basics`, `movie_ratings`) are read into pandas DataFrames. The head of each DataFrame is previewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45c8bd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/bom.movie_gross.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8719e84d259a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load CSV/TSV files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_bom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/bom.movie_gross.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf_rt_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/rt.movie_info.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_rt_reviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/rt.reviews.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DAVID\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DAVID\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DAVID\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DAVID\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DAVID\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DAVID\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/bom.movie_gross.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load CSV/TSV files\n",
    "df_bom = pd.read_csv('Data/bom.movie_gross.csv')\n",
    "df_rt_info = pd.read_csv('Data/rt.movie_info.tsv', sep='\\t')\n",
    "df_rt_reviews = pd.read_csv('Data/rt.reviews.tsv', sep='\\t', encoding='latin-1', low_memory=False)\n",
    "df_tmdb = pd.read_csv('Data/tmdb.movies.csv')\n",
    "df_tn = pd.read_csv('Data/tn.movie_budgets.csv')\n",
    "\n",
    "# Connect to IMDB SQLite database and load tables\n",
    "conn = sqlite3.connect(r'Data/im.db')\n",
    "df_imdb_basics = pd.read_sql_query(\"SELECT * FROM movie_basics\", conn)\n",
    "df_imdb_ratings = pd.read_sql_query(\"SELECT * FROM movie_ratings\", conn)\n",
    "\n",
    "# Preview heads\n",
    "display(df_bom.head())\n",
    "display(df_rt_info.head())\n",
    "display(df_rt_reviews.head())\n",
    "display(df_tmdb.head())\n",
    "display(df_tn.head())\n",
    "display(df_imdb_basics.head())\n",
    "display(df_imdb_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a263ff",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration\n",
    "\n",
    "Explore the structure, missing values, and key columns of each DataFrame (including IMDB). Identify variables relevant to profitability, genre, ratings, and merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore structure and missing values\n",
    "for name, df in [\n",
    "    (\"BOM\", df_bom),\n",
    "    (\"RottenTomatoes Info\", df_rt_info),\n",
    "    (\"RottenTomatoes Reviews\", df_rt_reviews),\n",
    "    (\"TMDB\", df_tmdb),\n",
    "    (\"TheNumbers\", df_tn),\n",
    "    (\"IMDB Basics\", df_imdb_basics),\n",
    "    (\"IMDB Ratings\", df_imdb_ratings)\n",
    "]:\n",
    "    print(f\"\\n{name} columns: {df.columns.tolist()}\")\n",
    "    print(df.info())\n",
    "    print(df.isnull().sum())\n",
    "    display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81715945",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Standardization\n",
    "\n",
    "Clean all DataFrames: handle missing values, standardize column names and types, remove duplicates, and ensure consistent formatting (e.g., lowercase titles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BOM ---\n",
    "df_bom['studio'] = df_bom['studio'].fillna('Unknown')\n",
    "df_bom['domestic_gross'] = pd.to_numeric(df_bom['domestic_gross'], errors='coerce')\n",
    "df_bom['foreign_gross'] = pd.to_numeric(df_bom['foreign_gross'], errors='coerce')\n",
    "df_bom['title'] = df_bom['title'].str.lower()\n",
    "df_bom = df_bom.rename(columns={'title': 'bom_title'})\n",
    "df_bom = df_bom.drop_duplicates()\n",
    "\n",
    "# --- RottenTomatoes Info ---\n",
    "for col in ['rating', 'genre', 'director', 'writer', 'studio']:\n",
    "    if col in df_rt_info.columns:\n",
    "        df_rt_info[col] = df_rt_info[col].fillna(df_rt_info[col].mode()[0])\n",
    "df_rt_info['theater_date'] = pd.to_datetime(df_rt_info['theater_date'], errors='coerce')\n",
    "df_rt_info['dvd_date'] = pd.to_datetime(df_rt_info['dvd_date'], errors='coerce')\n",
    "if 'box_office' in df_rt_info.columns:\n",
    "    df_rt_info['box_office'] = df_rt_info['box_office'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "if 'movie title' in df_rt_info.columns:\n",
    "    df_rt_info['movie title'] = df_rt_info['movie title'].str.lower()\n",
    "    df_rt_info = df_rt_info.rename(columns={'movie title': 'rt_movie_title'})\n",
    "df_rt_info = df_rt_info.drop_duplicates()\n",
    "\n",
    "# --- RottenTomatoes Reviews ---\n",
    "if 'review' in df_rt_reviews.columns:\n",
    "    df_rt_reviews = df_rt_reviews.dropna(subset=['review'])\n",
    "if 'date' in df_rt_reviews.columns:\n",
    "    df_rt_reviews['date'] = pd.to_datetime(df_rt_reviews['date'], errors='coerce')\n",
    "df_rt_reviews = df_rt_reviews.drop_duplicates()\n",
    "\n",
    "# --- TMDB ---\n",
    "df_tmdb = df_tmdb.dropna()\n",
    "df_tmdb['title'] = df_tmdb['title'].str.lower()\n",
    "df_tmdb['original_title'] = df_tmdb['original_title'].str.lower()\n",
    "df_tmdb['release_date'] = pd.to_datetime(df_tmdb['release_date'], errors='coerce')\n",
    "df_tmdb = df_tmdb.rename(columns={'title': 'tmdb_title', 'original_title': 'tmdb_original_title'})\n",
    "if 'Unnamed: 0' in df_tmdb.columns:\n",
    "    df_tmdb = df_tmdb.drop(columns=['Unnamed: 0'])\n",
    "df_tmdb = df_tmdb.drop_duplicates()\n",
    "\n",
    "# --- TheNumbers ---\n",
    "for col in ['production_budget', 'domestic_gross', 'worldwide_gross']:\n",
    "    df_tn[col] = df_tn[col].replace('[\\$,]', '', regex=True).astype(float)\n",
    "df_tn['release_date'] = pd.to_datetime(df_tn['release_date'], errors='coerce')\n",
    "df_tn['movie'] = df_tn['movie'].str.lower()\n",
    "df_tn = df_tn.rename(columns={'movie': 'tn_movie'})\n",
    "df_tn = df_tn.drop_duplicates()\n",
    "\n",
    "# --- IMDB Basics ---\n",
    "df_imdb_basics['primary_title'] = df_imdb_basics['primary_title'].str.lower()\n",
    "df_imdb_basics = df_imdb_basics.drop_duplicates()\n",
    "\n",
    "# --- IMDB Ratings ---\n",
    "df_imdb_ratings = df_imdb_ratings.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b005e6",
   "metadata": {},
   "source": [
    "## 4. Merge Datasets with Title and ID Matching\n",
    "\n",
    "Merge all datasets into a single DataFrame. Use exact and fuzzy matching on movie titles and IDs. Integrate IMDB genre and rating data. Document and handle merge issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696fdbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "# Merge IMDB basics and ratings\n",
    "df_imdb = pd.merge(df_imdb_basics, df_imdb_ratings, on='movie_id', how='left')\n",
    "\n",
    "# Merge TheNumbers and BOM on movie title (exact)\n",
    "df_merged = pd.merge(df_tn, df_bom, left_on='tn_movie', right_on='bom_title', how='left')\n",
    "\n",
    "# Merge with TMDB on title (fuzzy)\n",
    "def fuzzy_merge_titles(df_left, df_right, left_on, right_on, threshold=85):\n",
    "    matches = []\n",
    "    for left_value in df_left[left_on]:\n",
    "        best_match = process.extractOne(left_value, df_right[right_on], scorer=fuzz.token_sort_ratio, score_cutoff=threshold)\n",
    "        if best_match:\n",
    "            matches.append(best_match[0])\n",
    "        else:\n",
    "            matches.append(None)\n",
    "    df_left['tmdb_match_title'] = matches\n",
    "    merged = pd.merge(df_left, df_right, left_on='tmdb_match_title', right_on=right_on, how='left')\n",
    "    return merged\n",
    "\n",
    "df_merged = fuzzy_merge_titles(df_merged, df_tmdb, 'tn_movie', 'tmdb_title')\n",
    "\n",
    "# Merge with IMDB on title (fuzzy)\n",
    "df_merged['imdb_match_title'] = [\n",
    "    process.extractOne(title, df_imdb['primary_title'], scorer=fuzz.token_sort_ratio, score_cutoff=85)[0]\n",
    "    if process.extractOne(title, df_imdb['primary_title'], scorer=fuzz.token_sort_ratio, score_cutoff=85)\n",
    "    else None\n",
    "    for title in df_merged['tn_movie']\n",
    "]\n",
    "df_merged = pd.merge(df_merged, df_imdb, left_on='imdb_match_title', right_on='primary_title', how='left')\n",
    "\n",
    "# Merge with RottenTomatoes Info (fuzzy)\n",
    "df_merged['rt_match_title'] = [\n",
    "    process.extractOne(title, df_rt_info['rt_movie_title'], scorer=fuzz.token_sort_ratio, score_cutoff=85)[0]\n",
    "    if process.extractOne(title, df_rt_info['rt_movie_title'], scorer=fuzz.token_sort_ratio, score_cutoff=85)\n",
    "    else None\n",
    "    for title in df_merged['tn_movie']\n",
    "]\n",
    "df_merged = pd.merge(df_merged, df_rt_info, left_on='rt_match_title', right_on='rt_movie_title', how='left')\n",
    "\n",
    "# Note: RottenTomatoes Reviews are not merged directly due to lack of unique title or ID mapping.\n",
    "\n",
    "display(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05833c54",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering (Profit, Date, Genre, Review Scores)\n",
    "\n",
    "Create new features: profit margin, release year/month, genre dummies, and aggregated review scores (using IMDB and other sources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit Margin\n",
    "df_merged['profit_margin'] = df_merged['worldwide_gross'] - df_merged['production_budget']\n",
    "\n",
    "# Release Year/Month (prefer TheNumbers, fallback to TMDB/IMDB)\n",
    "if 'release_date_x' in df_merged.columns:\n",
    "    df_merged['release_date'] = df_merged['release_date_x']\n",
    "elif 'release_date' in df_merged.columns:\n",
    "    df_merged['release_date'] = df_merged['release_date']\n",
    "elif 'release_date_y' in df_merged.columns:\n",
    "    df_merged['release_date'] = df_merged['release_date_y']\n",
    "else:\n",
    "    df_merged['release_date'] = pd.NaT\n",
    "\n",
    "df_merged['release_year'] = pd.to_datetime(df_merged['release_date'], errors='coerce').dt.year\n",
    "df_merged['release_month'] = pd.to_datetime(df_merged['release_date'], errors='coerce').dt.month\n",
    "\n",
    "# Genre Dummies (prefer IMDB, fallback to RT or TMDB)\n",
    "if 'genres' in df_merged.columns and df_merged['genres'].notnull().any():\n",
    "    genres = df_merged['genres'].str.get_dummies(sep=',')\n",
    "elif 'genre' in df_merged.columns and df_merged['genre'].notnull().any():\n",
    "    genres = df_merged['genre'].str.get_dummies(sep=',')\n",
    "elif 'genres_y' in df_merged.columns and df_merged['genres_y'].notnull().any():\n",
    "    genres = df_merged['genres_y'].str.get_dummies(sep=',')\n",
    "else:\n",
    "    genres = pd.DataFrame()\n",
    "\n",
    "if not genres.empty:\n",
    "    df_merged = pd.concat([df_merged, genres], axis=1)\n",
    "\n",
    "# Aggregated Review Score (IMDB, fallback to TMDB/RT)\n",
    "if 'average_rating' in df_merged.columns and df_merged['average_rating'].notnull().any():\n",
    "    df_merged['aggregated_review_score'] = df_merged['average_rating']\n",
    "elif 'vote_average' in df_merged.columns and df_merged['vote_average'].notnull().any():\n",
    "    df_merged['aggregated_review_score'] = df_merged['vote_average']\n",
    "elif 'tomatometer_rating' in df_merged.columns and df_merged['tomatometer_rating'].notnull().any():\n",
    "    df_merged['aggregated_review_score'] = df_merged['tomatometer_rating']\n",
    "else:\n",
    "    df_merged['aggregated_review_score'] = None\n",
    "\n",
    "display(df_merged[['tn_movie', 'profit_margin', 'release_year', 'release_month', 'aggregated_review_score'] + (genres.columns.tolist() if not genres.empty else [])].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278da07",
   "metadata": {},
   "source": [
    "## 6. Genre Profitability Analysis\n",
    "\n",
    "Group by genre and calculate average profit margin. Identify most and least profitable genres. Visualize results with a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81522c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use IMDB genres if available\n",
    "if 'genres' in df_merged.columns and df_merged['genres'].notnull().any():\n",
    "    genre_col = 'genres'\n",
    "elif 'genre' in df_merged.columns and df_merged['genre'].notnull().any():\n",
    "    genre_col = 'genre'\n",
    "elif 'genres_y' in df_merged.columns and df_merged['genres_y'].notnull().any():\n",
    "    genre_col = 'genres_y'\n",
    "else:\n",
    "    genre_col = None\n",
    "\n",
    "if genre_col:\n",
    "    # Explode genres for multi-genre movies\n",
    "    df_exploded = df_merged.dropna(subset=[genre_col, 'profit_margin']).copy()\n",
    "    df_exploded[genre_col] = df_exploded[genre_col].str.split(',')\n",
    "    df_exploded = df_exploded.explode(genre_col)\n",
    "    df_exploded[genre_col] = df_exploded[genre_col].str.strip()\n",
    "    genre_profit = df_exploded.groupby(genre_col)['profit_margin'].mean().sort_values(ascending=False)\n",
    "    print(\"Most Profitable Genre:\", genre_profit.index[0])\n",
    "    print(\"Least Profitable Genre:\", genre_profit.index[-1])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=genre_profit.index, y=genre_profit.values, palette='viridis')\n",
    "    plt.title('Average Profit Margin by Genre')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Average Profit Margin')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No genre column found for profitability analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d0430",
   "metadata": {},
   "source": [
    "## 7. Budget vs Revenue Analysis\n",
    "\n",
    "Calculate and visualize the correlation between production budget and worldwide gross revenue using scatter plots and correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for correlation\n",
    "df_corr = df_merged.dropna(subset=['production_budget', 'worldwide_gross'])\n",
    "corr = df_corr['production_budget'].corr(df_corr['worldwide_gross'])\n",
    "print(f\"Pearson correlation coefficient between budget and revenue: {corr:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_corr['production_budget'], df_corr['worldwide_gross'], alpha=0.5)\n",
    "plt.title('Production Budget vs. Worldwide Gross Revenue')\n",
    "plt.xlabel('Production Budget')\n",
    "plt.ylabel('Worldwide Gross Revenue')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90fdb3",
   "metadata": {},
   "source": [
    "## 8. Review Scores vs Revenue Analysis\n",
    "\n",
    "Analyze and visualize the relationship between aggregated review scores and worldwide gross revenue using scatter plots and correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_merged.dropna(subset=['aggregated_review_score', 'worldwide_gross'])\n",
    "corr_review = df_review['aggregated_review_score'].corr(df_review['worldwide_gross'])\n",
    "print(f\"Pearson correlation coefficient between aggregated review score and revenue: {corr_review:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_review['aggregated_review_score'], df_review['worldwide_gross'], color='purple', alpha=0.6)\n",
    "plt.title('Aggregated Review Score vs. Worldwide Gross Revenue')\n",
    "plt.xlabel('Aggregated Review Score')\n",
    "plt.ylabel('Worldwide Gross Revenue')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2dbaf1",
   "metadata": {},
   "source": [
    "## 9. Visualization of Key Findings\n",
    "\n",
    "Summarize actionable insights for stakeholders and present clear visualizations for genre profitability, budget vs revenue, and review score vs revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4717f5f",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "- **Most Profitable Genres:** The genre profitability analysis (see bar chart above) reveals which genres yield the highest average profit margins.\n",
    "- **Budget-Revenue Relationship:** There is a strong positive correlation between production budget and worldwide gross revenue.\n",
    "- **Review Scores Impact:** There is a weak-to-moderate positive correlation between aggregated review scores and worldwide gross revenue.\n",
    "\n",
    "### Actionable Insights\n",
    "\n",
    "- **Focus on Profitable Genres:** Prioritize genres with the highest average profit margins for new productions.\n",
    "- **Budget Allocation:** Higher budgets are generally associated with higher revenues, but ROI should be considered.\n",
    "- **Quality Matters:** While review scores have a weaker correlation with revenue, higher-rated movies tend to perform better.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Further refine genre mapping and consider sub-genres.\n",
    "- Explore advanced regression models to control for confounding variables.\n",
    "- Investigate outliers and exceptions for deeper business insights.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
